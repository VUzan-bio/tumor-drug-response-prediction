data:
  # Root directory for processed parquet tables and splits.
  processed_dir: "data/processed"
  omics_file: "omics.parquet"
  drug_file: "drug_fingerprints.parquet"
  labels_file: "labels.parquet"
  metadata_file: "metadata.parquet"
  # Keep top-variance genes to reduce noise and dimensionality.
  n_genes: 2000
  # Morgan fingerprint length; standard sizes are 512/1024/2048.
  fingerprint_bits: 1024

model:
  # Enable VAE to denoise omics features; tune with ablations.
  use_vae: false
  # These are auto-overwritten at runtime based on processed data shapes.
  omics_dim: 2000
  omics_latent_dim: 128
  drug_dim: 1024
  # Fusion MLP applied to concatenated omics/drug latents.
  fusion_hidden_dims: [256, 128]
  # Dropout for encoders and fusion MLP.
  dropout: 0.2

training:
  # Batch size tuned for moderate GPU/CPU memory footprints.
  batch_size: 128
  # Adam learning rate; adjust alongside batch size.
  lr: 0.001
  weight_decay: 0.0001
  max_epochs: 100
  # Legacy split strategy for fusion training; CSV splits live in scripts/make_splits.py.
  split_strategy: "leave_cell_line_out"
  k_folds: 5
  # Required when split_strategy == tissue_holdout.
  tissue_holdout: null
  seed: 42
  num_workers: 4
  device: "cpu"
